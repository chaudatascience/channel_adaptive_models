{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d065759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from trainer import Trainer\n",
    "from os.path import join as os_join\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6bf9254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "  batch_strategy: random_instance\n",
      "  resume_train: false\n",
      "  resume_model: hypernet.pt\n",
      "  use_amp: false\n",
      "  checkpoints: ../STORE/adaptive_interface/checkpoints\n",
      "  save_model: no_save\n",
      "  clip_grad_norm: null\n",
      "  batch_size: 128\n",
      "  num_epochs: 15\n",
      "  verbose_batches: 50\n",
      "  seed: 125617\n",
      "  debug: false\n",
      "  adaptive_interface_epochs: 0\n",
      "  adaptive_interface_lr: null\n",
      "  swa: false\n",
      "  swad: false\n",
      "  swa_lr: 0.05\n",
      "  swa_start: 5\n",
      "  miro: false\n",
      "  miro_lr_mult: 10.0\n",
      "  miro_ld: 0.01\n",
      "  tps_prob: 0.0\n",
      "model:\n",
      "  name: hyperconvnext\n",
      "  pretrained: true\n",
      "  pretrained_model_name: convnext_tiny.fb_in22k\n",
      "  in_dim: null\n",
      "  num_classes: null\n",
      "  pooling: avg\n",
      "  temperature: 0.07\n",
      "  learnable_temp: false\n",
      "  unfreeze_last_n_layers: -1\n",
      "  unfreeze_first_layer: true\n",
      "  first_layer: reinit_as_random\n",
      "  reset_last_n_unfrozen_layers: false\n",
      "  use_auto_rgn: false\n",
      "  z_dim: 128\n",
      "  hidden_dim: 256\n",
      "  in_channel_names:\n",
      "  - er\n",
      "  - golgi\n",
      "  - membrane\n",
      "  - microtubules\n",
      "  - mito\n",
      "  - nucleus\n",
      "  - protein\n",
      "  - rna\n",
      "  separate_emb: true\n",
      "scheduler:\n",
      "  name: cosine\n",
      "  convert_to_batch: false\n",
      "  params:\n",
      "    t_initial: FILL_LATER\n",
      "    lr_min: 1.0e-06\n",
      "    cycle_mul: 1.0\n",
      "    cycle_decay: 0.5\n",
      "    cycle_limit: 1\n",
      "    warmup_t: 3\n",
      "    warmup_lr_init: 1.0e-05\n",
      "    warmup_prefix: false\n",
      "    t_in_epochs: true\n",
      "    noise_range_t: null\n",
      "    noise_pct: 0.67\n",
      "    noise_std: 1.0\n",
      "    noise_seed: 42\n",
      "    k_decay: 1.0\n",
      "    initialize: true\n",
      "optimizer:\n",
      "  name: adamw\n",
      "  params:\n",
      "    lr: 0.0004\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 5.0e-05\n",
      "    amsgrad: false\n",
      "dataset:\n",
      "  name: morphem70k\n",
      "  img_size: 224\n",
      "  root_dir: /projectnb/morphem/data_70k/ver2/morphem_70k_version2\n",
      "  file_name: morphem70k_v2.csv\n",
      "data_chunk:\n",
      "  chunks:\n",
      "  - Allen:\n",
      "    - nucleus\n",
      "    - membrane\n",
      "    - protein\n",
      "  - HPA:\n",
      "    - microtubules\n",
      "    - protein\n",
      "    - nucleus\n",
      "    - er\n",
      "  - CP:\n",
      "    - nucleus\n",
      "    - er\n",
      "    - rna\n",
      "    - golgi\n",
      "    - mito\n",
      "logging:\n",
      "  wandb:\n",
      "    use_wandb: false\n",
      "    log_freq: 10000\n",
      "    num_images_to_log: 0\n",
      "    project_name: null\n",
      "  use_py_log: false\n",
      "  scc_jobid: null\n",
      "hardware:\n",
      "  num_workers: 3\n",
      "  device: cuda\n",
      "  multi_gpus: null\n",
      "eval:\n",
      "  batch_size: null\n",
      "  dest_dir: ../STORE/adaptive_interface/snapshots/{FOLDER_NAME}/results\n",
      "  feature_dir: ../STORE/adaptive_interface/snapshots/{FOLDER_NAME}/features\n",
      "  root_dir: /projectnb/morphem/data_70k/ver2/morphem_70k_version2/\n",
      "  meta_csv_file: FILL_LATER\n",
      "  classifiers:\n",
      "  - knn\n",
      "  - sgd\n",
      "  classifier: PLACE_HOLDER\n",
      "  feature_file: features.npy\n",
      "  use_gpu: true\n",
      "  knn_metric: PLACE_HOLDER\n",
      "  knn_metrics:\n",
      "  - l2\n",
      "  - cosine\n",
      "  clean_up: false\n",
      "  umap: true\n",
      "  only_eval_first_and_last: false\n",
      "attn_pooling: {}\n",
      "tag: hyper\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## read yaml file that stored the config of the model checkpoint\n",
    "path = \"checkpoint_configs/hypernet.yaml\"\n",
    "cfg = OmegaConf.load(path)\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8471a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quick test on 1 image\n",
    "cfg[\"eval\"][\"batch_size\"] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbe65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "chunks [{'Allen': ['nucleus', 'membrane', 'protein']}, {'HPA': ['microtubules', 'protein', 'nucleus', 'er']}, {'CP': ['nucleus', 'er', 'rna', 'golgi', 'mito']}]\n",
      "channels [3, 4, 5]\n",
      "train:\n",
      "  batch_strategy: random_instance\n",
      "  resume_train: false\n",
      "  resume_model: hypernet.pt\n",
      "  use_amp: false\n",
      "  checkpoints: ../STORE/adaptive_interface/checkpoints\n",
      "  save_model: no_save\n",
      "  clip_grad_norm: null\n",
      "  batch_size: 128\n",
      "  num_epochs: 15\n",
      "  verbose_batches: 50\n",
      "  seed: 125617\n",
      "  debug: false\n",
      "  adaptive_interface_epochs: 0\n",
      "  adaptive_interface_lr: 0.04\n",
      "  swa: false\n",
      "  swad: false\n",
      "  swa_lr: 0.05\n",
      "  swa_start: 5\n",
      "  miro: false\n",
      "  miro_lr_mult: 10.0\n",
      "  miro_ld: 0.01\n",
      "  tps_prob: 0.0\n",
      "model:\n",
      "  name: hyperconvnext\n",
      "  pretrained: true\n",
      "  pretrained_model_name: convnext_tiny.fb_in22k\n",
      "  in_dim: 5\n",
      "  num_classes: 14\n",
      "  pooling: avg\n",
      "  temperature: 0.07\n",
      "  learnable_temp: false\n",
      "  unfreeze_last_n_layers: -1\n",
      "  unfreeze_first_layer: true\n",
      "  first_layer: reinit_as_random\n",
      "  reset_last_n_unfrozen_layers: false\n",
      "  use_auto_rgn: false\n",
      "  z_dim: 128\n",
      "  hidden_dim: 256\n",
      "  in_channel_names:\n",
      "  - er\n",
      "  - golgi\n",
      "  - membrane\n",
      "  - microtubules\n",
      "  - mito\n",
      "  - nucleus\n",
      "  - protein\n",
      "  - rna\n",
      "  separate_emb: true\n",
      "scheduler:\n",
      "  name: cosine\n",
      "  convert_to_batch: false\n",
      "  params:\n",
      "    t_initial: FILL_LATER\n",
      "    lr_min: 1.0e-06\n",
      "    cycle_mul: 1.0\n",
      "    cycle_decay: 0.5\n",
      "    cycle_limit: 1\n",
      "    warmup_t: 3\n",
      "    warmup_lr_init: 1.0e-05\n",
      "    warmup_prefix: false\n",
      "    t_in_epochs: true\n",
      "    noise_range_t: null\n",
      "    noise_pct: 0.67\n",
      "    noise_std: 1.0\n",
      "    noise_seed: 42\n",
      "    k_decay: 1.0\n",
      "    initialize: true\n",
      "optimizer:\n",
      "  name: adamw\n",
      "  params:\n",
      "    lr: 0.0004\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 5.0e-05\n",
      "    amsgrad: false\n",
      "dataset:\n",
      "  name: morphem70k\n",
      "  img_size: 224\n",
      "  root_dir: /projectnb/morphem/data_70k/ver2/morphem_70k_version2\n",
      "  file_name: morphem70k_v2.csv\n",
      "data_chunk:\n",
      "  chunks:\n",
      "  - Allen:\n",
      "    - nucleus\n",
      "    - membrane\n",
      "    - protein\n",
      "  - HPA:\n",
      "    - microtubules\n",
      "    - protein\n",
      "    - nucleus\n",
      "    - er\n",
      "  - CP:\n",
      "    - nucleus\n",
      "    - er\n",
      "    - rna\n",
      "    - golgi\n",
      "    - mito\n",
      "logging:\n",
      "  wandb:\n",
      "    use_wandb: false\n",
      "    log_freq: 10000\n",
      "    num_images_to_log: 0\n",
      "    project_name: morphem_rebuttal\n",
      "  use_py_log: false\n",
      "  scc_jobid: null\n",
      "hardware:\n",
      "  num_workers: 3\n",
      "  device: cuda\n",
      "  multi_gpus: null\n",
      "eval:\n",
      "  batch_size: 1\n",
      "  dest_dir: ../STORE/adaptive_interface/snapshots/{FOLDER_NAME}/results\n",
      "  feature_dir: ../STORE/adaptive_interface/snapshots/{FOLDER_NAME}/features\n",
      "  root_dir: /projectnb/morphem/data_70k/ver2/morphem_70k_version2/\n",
      "  meta_csv_file: enriched_meta_v2.csv\n",
      "  classifiers:\n",
      "  - knn\n",
      "  - sgd\n",
      "  classifier: PLACE_HOLDER\n",
      "  feature_file: features.npy\n",
      "  use_gpu: true\n",
      "  knn_metric: PLACE_HOLDER\n",
      "  knn_metrics:\n",
      "  - l2\n",
      "  - cosine\n",
      "  clean_up: false\n",
      "  umap: true\n",
      "  only_eval_first_and_last: false\n",
      "attn_pooling: {}\n",
      "tag: hyper\n",
      "\n",
      "HyperConvNeXt(\n",
      "  (conv1_emb): ParameterDict(\n",
      "      (Allen): Parameter containing: [torch.cuda.FloatTensor of size 3x128 (GPU 0)]\n",
      "      (CP): Parameter containing: [torch.cuda.FloatTensor of size 5x128 (GPU 0)]\n",
      "      (HPA): Parameter containing: [torch.cuda.FloatTensor of size 4x128 (GPU 0)]\n",
      "  )\n",
      "  (hypernet): HyperNetwork()\n",
      "  (adaptive_interface): ModuleList(\n",
      "    (0): ParameterDict(\n",
      "        (Allen): Parameter containing: [torch.cuda.FloatTensor of size 3x128 (GPU 0)]\n",
      "        (CP): Parameter containing: [torch.cuda.FloatTensor of size 5x128 (GPU 0)]\n",
      "        (HPA): Parameter containing: [torch.cuda.FloatTensor of size 4x128 (GPU 0)]\n",
      "    )\n",
      "    (1): HyperNetwork()\n",
      "  )\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "    (1): ConvNeXtStage(\n",
      "      (downsample): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ConvNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvNeXtBlock(\n",
      "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (4): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (5): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (6): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (7): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (8): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (9): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (10): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (11): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (12): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (13): Sequential(\n",
      "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (14): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (15): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (16): ConvNeXtBlock(\n",
      "      (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU()\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[   'proxies',\n",
      "    'conv1_emb.Allen',\n",
      "    'conv1_emb.CP',\n",
      "    'conv1_emb.HPA',\n",
      "    'hypernet.W',\n",
      "    'hypernet.b',\n",
      "    'hypernet.W_out',\n",
      "    'hypernet.b_out',\n",
      "    'adaptive_interface.0.Allen',\n",
      "    'adaptive_interface.0.CP',\n",
      "    'adaptive_interface.0.HPA',\n",
      "    'adaptive_interface.1.W',\n",
      "    'adaptive_interface.1.b',\n",
      "    'adaptive_interface.1.W_out',\n",
      "    'adaptive_interface.1.b_out',\n",
      "    'feature_extractor.0.weight',\n",
      "    'feature_extractor.0.bias',\n",
      "    'feature_extractor.1.blocks.0.gamma',\n",
      "    'feature_extractor.1.blocks.0.conv_dw.weight',\n",
      "    'feature_extractor.1.blocks.0.conv_dw.bias',\n",
      "    'feature_extractor.1.blocks.0.norm.weight',\n",
      "    'feature_extractor.1.blocks.0.norm.bias',\n",
      "    'feature_extractor.1.blocks.0.mlp.fc1.weight',\n",
      "    'feature_extractor.1.blocks.0.mlp.fc1.bias',\n",
      "    'feature_extractor.1.blocks.0.mlp.fc2.weight',\n",
      "    'feature_extractor.1.blocks.0.mlp.fc2.bias',\n",
      "    'feature_extractor.1.blocks.1.gamma',\n",
      "    'feature_extractor.1.blocks.1.conv_dw.weight',\n",
      "    'feature_extractor.1.blocks.1.conv_dw.bias',\n",
      "    'feature_extractor.1.blocks.1.norm.weight',\n",
      "    'feature_extractor.1.blocks.1.norm.bias',\n",
      "    'feature_extractor.1.blocks.1.mlp.fc1.weight',\n",
      "    'feature_extractor.1.blocks.1.mlp.fc1.bias',\n",
      "    'feature_extractor.1.blocks.1.mlp.fc2.weight',\n",
      "    'feature_extractor.1.blocks.1.mlp.fc2.bias',\n",
      "    'feature_extractor.1.blocks.2.gamma',\n",
      "    'feature_extractor.1.blocks.2.conv_dw.weight',\n",
      "    'feature_extractor.1.blocks.2.conv_dw.bias',\n",
      "    'feature_extractor.1.blocks.2.norm.weight',\n",
      "    'feature_extractor.1.blocks.2.norm.bias',\n",
      "    'feature_extractor.1.blocks.2.mlp.fc1.weight',\n",
      "    'feature_extractor.1.blocks.2.mlp.fc1.bias',\n",
      "    'feature_extractor.1.blocks.2.mlp.fc2.weight',\n",
      "    'feature_extractor.1.blocks.2.mlp.fc2.bias',\n",
      "    'feature_extractor.2.downsample.0.weight',\n",
      "    'feature_extractor.2.downsample.0.bias',\n",
      "    'feature_extractor.2.downsample.1.weight',\n",
      "    'feature_extractor.2.downsample.1.bias',\n",
      "    'feature_extractor.2.blocks.0.gamma',\n",
      "    'feature_extractor.2.blocks.0.conv_dw.weight',\n",
      "    'feature_extractor.2.blocks.0.conv_dw.bias',\n",
      "    'feature_extractor.2.blocks.0.norm.weight',\n",
      "    'feature_extractor.2.blocks.0.norm.bias',\n",
      "    'feature_extractor.2.blocks.0.mlp.fc1.weight',\n",
      "    'feature_extractor.2.blocks.0.mlp.fc1.bias',\n",
      "    'feature_extractor.2.blocks.0.mlp.fc2.weight',\n",
      "    'feature_extractor.2.blocks.0.mlp.fc2.bias',\n",
      "    'feature_extractor.2.blocks.1.gamma',\n",
      "    'feature_extractor.2.blocks.1.conv_dw.weight',\n",
      "    'feature_extractor.2.blocks.1.conv_dw.bias',\n",
      "    'feature_extractor.2.blocks.1.norm.weight',\n",
      "    'feature_extractor.2.blocks.1.norm.bias',\n",
      "    'feature_extractor.2.blocks.1.mlp.fc1.weight',\n",
      "    'feature_extractor.2.blocks.1.mlp.fc1.bias',\n",
      "    'feature_extractor.2.blocks.1.mlp.fc2.weight',\n",
      "    'feature_extractor.2.blocks.1.mlp.fc2.bias',\n",
      "    'feature_extractor.2.blocks.2.gamma',\n",
      "    'feature_extractor.2.blocks.2.conv_dw.weight',\n",
      "    'feature_extractor.2.blocks.2.conv_dw.bias',\n",
      "    'feature_extractor.2.blocks.2.norm.weight',\n",
      "    'feature_extractor.2.blocks.2.norm.bias',\n",
      "    'feature_extractor.2.blocks.2.mlp.fc1.weight',\n",
      "    'feature_extractor.2.blocks.2.mlp.fc1.bias',\n",
      "    'feature_extractor.2.blocks.2.mlp.fc2.weight',\n",
      "    'feature_extractor.2.blocks.2.mlp.fc2.bias',\n",
      "    'feature_extractor.3.0.weight',\n",
      "    'feature_extractor.3.0.bias',\n",
      "    'feature_extractor.3.1.weight',\n",
      "    'feature_extractor.3.1.bias',\n",
      "    'feature_extractor.4.gamma',\n",
      "    'feature_extractor.4.conv_dw.weight',\n",
      "    'feature_extractor.4.conv_dw.bias',\n",
      "    'feature_extractor.4.norm.weight',\n",
      "    'feature_extractor.4.norm.bias',\n",
      "    'feature_extractor.4.mlp.fc1.weight',\n",
      "    'feature_extractor.4.mlp.fc1.bias',\n",
      "    'feature_extractor.4.mlp.fc2.weight',\n",
      "    'feature_extractor.4.mlp.fc2.bias',\n",
      "    'feature_extractor.5.gamma',\n",
      "    'feature_extractor.5.conv_dw.weight',\n",
      "    'feature_extractor.5.conv_dw.bias',\n",
      "    'feature_extractor.5.norm.weight',\n",
      "    'feature_extractor.5.norm.bias',\n",
      "    'feature_extractor.5.mlp.fc1.weight',\n",
      "    'feature_extractor.5.mlp.fc1.bias',\n",
      "    'feature_extractor.5.mlp.fc2.weight',\n",
      "    'feature_extractor.5.mlp.fc2.bias',\n",
      "    'feature_extractor.6.gamma',\n",
      "    'feature_extractor.6.conv_dw.weight',\n",
      "    'feature_extractor.6.conv_dw.bias',\n",
      "    'feature_extractor.6.norm.weight',\n",
      "    'feature_extractor.6.norm.bias',\n",
      "    'feature_extractor.6.mlp.fc1.weight',\n",
      "    'feature_extractor.6.mlp.fc1.bias',\n",
      "    'feature_extractor.6.mlp.fc2.weight',\n",
      "    'feature_extractor.6.mlp.fc2.bias',\n",
      "    'feature_extractor.7.gamma',\n",
      "    'feature_extractor.7.conv_dw.weight',\n",
      "    'feature_extractor.7.conv_dw.bias',\n",
      "    'feature_extractor.7.norm.weight',\n",
      "    'feature_extractor.7.norm.bias',\n",
      "    'feature_extractor.7.mlp.fc1.weight',\n",
      "    'feature_extractor.7.mlp.fc1.bias',\n",
      "    'feature_extractor.7.mlp.fc2.weight',\n",
      "    'feature_extractor.7.mlp.fc2.bias',\n",
      "    'feature_extractor.8.gamma',\n",
      "    'feature_extractor.8.conv_dw.weight',\n",
      "    'feature_extractor.8.conv_dw.bias',\n",
      "    'feature_extractor.8.norm.weight',\n",
      "    'feature_extractor.8.norm.bias',\n",
      "    'feature_extractor.8.mlp.fc1.weight',\n",
      "    'feature_extractor.8.mlp.fc1.bias',\n",
      "    'feature_extractor.8.mlp.fc2.weight',\n",
      "    'feature_extractor.8.mlp.fc2.bias',\n",
      "    'feature_extractor.9.gamma',\n",
      "    'feature_extractor.9.conv_dw.weight',\n",
      "    'feature_extractor.9.conv_dw.bias',\n",
      "    'feature_extractor.9.norm.weight',\n",
      "    'feature_extractor.9.norm.bias',\n",
      "    'feature_extractor.9.mlp.fc1.weight',\n",
      "    'feature_extractor.9.mlp.fc1.bias',\n",
      "    'feature_extractor.9.mlp.fc2.weight',\n",
      "    'feature_extractor.9.mlp.fc2.bias',\n",
      "    'feature_extractor.10.gamma',\n",
      "    'feature_extractor.10.conv_dw.weight',\n",
      "    'feature_extractor.10.conv_dw.bias',\n",
      "    'feature_extractor.10.norm.weight',\n",
      "    'feature_extractor.10.norm.bias',\n",
      "    'feature_extractor.10.mlp.fc1.weight',\n",
      "    'feature_extractor.10.mlp.fc1.bias',\n",
      "    'feature_extractor.10.mlp.fc2.weight',\n",
      "    'feature_extractor.10.mlp.fc2.bias',\n",
      "    'feature_extractor.11.gamma',\n",
      "    'feature_extractor.11.conv_dw.weight',\n",
      "    'feature_extractor.11.conv_dw.bias',\n",
      "    'feature_extractor.11.norm.weight',\n",
      "    'feature_extractor.11.norm.bias',\n",
      "    'feature_extractor.11.mlp.fc1.weight',\n",
      "    'feature_extractor.11.mlp.fc1.bias',\n",
      "    'feature_extractor.11.mlp.fc2.weight',\n",
      "    'feature_extractor.11.mlp.fc2.bias',\n",
      "    'feature_extractor.12.gamma',\n",
      "    'feature_extractor.12.conv_dw.weight',\n",
      "    'feature_extractor.12.conv_dw.bias',\n",
      "    'feature_extractor.12.norm.weight',\n",
      "    'feature_extractor.12.norm.bias',\n",
      "    'feature_extractor.12.mlp.fc1.weight',\n",
      "    'feature_extractor.12.mlp.fc1.bias',\n",
      "    'feature_extractor.12.mlp.fc2.weight',\n",
      "    'feature_extractor.12.mlp.fc2.bias',\n",
      "    'feature_extractor.13.0.weight',\n",
      "    'feature_extractor.13.0.bias',\n",
      "    'feature_extractor.13.1.weight',\n",
      "    'feature_extractor.13.1.bias',\n",
      "    'feature_extractor.14.gamma',\n",
      "    'feature_extractor.14.conv_dw.weight',\n",
      "    'feature_extractor.14.conv_dw.bias',\n",
      "    'feature_extractor.14.norm.weight',\n",
      "    'feature_extractor.14.norm.bias',\n",
      "    'feature_extractor.14.mlp.fc1.weight',\n",
      "    'feature_extractor.14.mlp.fc1.bias',\n",
      "    'feature_extractor.14.mlp.fc2.weight',\n",
      "    'feature_extractor.14.mlp.fc2.bias',\n",
      "    'feature_extractor.15.gamma',\n",
      "    'feature_extractor.15.conv_dw.weight',\n",
      "    'feature_extractor.15.conv_dw.bias',\n",
      "    'feature_extractor.15.norm.weight',\n",
      "    'feature_extractor.15.norm.bias',\n",
      "    'feature_extractor.15.mlp.fc1.weight',\n",
      "    'feature_extractor.15.mlp.fc1.bias',\n",
      "    'feature_extractor.15.mlp.fc2.weight',\n",
      "    'feature_extractor.15.mlp.fc2.bias',\n",
      "    'feature_extractor.16.gamma',\n",
      "    'feature_extractor.16.conv_dw.weight',\n",
      "    'feature_extractor.16.conv_dw.bias',\n",
      "    'feature_extractor.16.norm.weight',\n",
      "    'feature_extractor.16.norm.bias',\n",
      "    'feature_extractor.16.mlp.fc1.weight',\n",
      "    'feature_extractor.16.mlp.fc1.bias',\n",
      "    'feature_extractor.16.mlp.fc2.weight',\n",
      "    'feature_extractor.16.mlp.fc2.bias']\n",
      "proxies torch.Size([14, 768]) 10752 True\n",
      "conv1_emb.Allen torch.Size([3, 128]) 384 True\n",
      "conv1_emb.CP torch.Size([5, 128]) 640 True\n",
      "conv1_emb.HPA torch.Size([4, 128]) 512 True\n",
      "hypernet.W torch.Size([128, 1, 256]) 32768 True\n",
      "hypernet.b torch.Size([1, 256]) 256 True\n",
      "hypernet.W_out torch.Size([256, 96, 4, 4]) 393216 True\n",
      "hypernet.b_out torch.Size([96, 4, 4]) 1536 True\n",
      "feature_extractor.0.weight torch.Size([96]) 96 True\n",
      "feature_extractor.0.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.0.gamma torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.0.conv_dw.weight torch.Size([96, 1, 7, 7]) 4704 True\n",
      "feature_extractor.1.blocks.0.conv_dw.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.0.norm.weight torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.0.norm.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.0.mlp.fc1.weight torch.Size([384, 96]) 36864 True\n",
      "feature_extractor.1.blocks.0.mlp.fc1.bias torch.Size([384]) 384 True\n",
      "feature_extractor.1.blocks.0.mlp.fc2.weight torch.Size([96, 384]) 36864 True\n",
      "feature_extractor.1.blocks.0.mlp.fc2.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.1.gamma torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.1.conv_dw.weight torch.Size([96, 1, 7, 7]) 4704 True\n",
      "feature_extractor.1.blocks.1.conv_dw.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.1.norm.weight torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.1.norm.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.1.mlp.fc1.weight torch.Size([384, 96]) 36864 True\n",
      "feature_extractor.1.blocks.1.mlp.fc1.bias torch.Size([384]) 384 True\n",
      "feature_extractor.1.blocks.1.mlp.fc2.weight torch.Size([96, 384]) 36864 True\n",
      "feature_extractor.1.blocks.1.mlp.fc2.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.2.gamma torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.2.conv_dw.weight torch.Size([96, 1, 7, 7]) 4704 True\n",
      "feature_extractor.1.blocks.2.conv_dw.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.2.norm.weight torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.2.norm.bias torch.Size([96]) 96 True\n",
      "feature_extractor.1.blocks.2.mlp.fc1.weight torch.Size([384, 96]) 36864 True\n",
      "feature_extractor.1.blocks.2.mlp.fc1.bias torch.Size([384]) 384 True\n",
      "feature_extractor.1.blocks.2.mlp.fc2.weight torch.Size([96, 384]) 36864 True\n",
      "feature_extractor.1.blocks.2.mlp.fc2.bias torch.Size([96]) 96 True\n",
      "feature_extractor.2.downsample.0.weight torch.Size([96]) 96 True\n",
      "feature_extractor.2.downsample.0.bias torch.Size([96]) 96 True\n",
      "feature_extractor.2.downsample.1.weight torch.Size([192, 96, 2, 2]) 73728 True\n",
      "feature_extractor.2.downsample.1.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.0.gamma torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.0.conv_dw.weight torch.Size([192, 1, 7, 7]) 9408 True\n",
      "feature_extractor.2.blocks.0.conv_dw.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.0.norm.weight torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.0.norm.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.0.mlp.fc1.weight torch.Size([768, 192]) 147456 True\n",
      "feature_extractor.2.blocks.0.mlp.fc1.bias torch.Size([768]) 768 True\n",
      "feature_extractor.2.blocks.0.mlp.fc2.weight torch.Size([192, 768]) 147456 True\n",
      "feature_extractor.2.blocks.0.mlp.fc2.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.1.gamma torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.1.conv_dw.weight torch.Size([192, 1, 7, 7]) 9408 True\n",
      "feature_extractor.2.blocks.1.conv_dw.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.1.norm.weight torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.1.norm.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.1.mlp.fc1.weight torch.Size([768, 192]) 147456 True\n",
      "feature_extractor.2.blocks.1.mlp.fc1.bias torch.Size([768]) 768 True\n",
      "feature_extractor.2.blocks.1.mlp.fc2.weight torch.Size([192, 768]) 147456 True\n",
      "feature_extractor.2.blocks.1.mlp.fc2.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.2.gamma torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.2.conv_dw.weight torch.Size([192, 1, 7, 7]) 9408 True\n",
      "feature_extractor.2.blocks.2.conv_dw.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.2.norm.weight torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.2.norm.bias torch.Size([192]) 192 True\n",
      "feature_extractor.2.blocks.2.mlp.fc1.weight torch.Size([768, 192]) 147456 True\n",
      "feature_extractor.2.blocks.2.mlp.fc1.bias torch.Size([768]) 768 True\n",
      "feature_extractor.2.blocks.2.mlp.fc2.weight torch.Size([192, 768]) 147456 True\n",
      "feature_extractor.2.blocks.2.mlp.fc2.bias torch.Size([192]) 192 True\n",
      "feature_extractor.3.0.weight torch.Size([192]) 192 True\n",
      "feature_extractor.3.0.bias torch.Size([192]) 192 True\n",
      "feature_extractor.3.1.weight torch.Size([384, 192, 2, 2]) 294912 True\n",
      "feature_extractor.3.1.bias torch.Size([384]) 384 True\n",
      "feature_extractor.4.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.4.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.4.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.4.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.4.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.4.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.4.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.4.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.4.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.5.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.5.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.5.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.5.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.5.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.5.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.5.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.5.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.5.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.6.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.6.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.6.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.6.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.6.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.6.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.6.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.6.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.6.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.7.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.7.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.7.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.7.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.7.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.7.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.7.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.7.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.7.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.8.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.8.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.8.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.8.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.8.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.8.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.8.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.8.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.8.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.9.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.9.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.9.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.9.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.9.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.9.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.9.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.9.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.9.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.10.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.10.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.10.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.10.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.10.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.10.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.10.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.10.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.10.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.11.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.11.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.11.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.11.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.11.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.11.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.11.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.11.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.11.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.12.gamma torch.Size([384]) 384 True\n",
      "feature_extractor.12.conv_dw.weight torch.Size([384, 1, 7, 7]) 18816 True\n",
      "feature_extractor.12.conv_dw.bias torch.Size([384]) 384 True\n",
      "feature_extractor.12.norm.weight torch.Size([384]) 384 True\n",
      "feature_extractor.12.norm.bias torch.Size([384]) 384 True\n",
      "feature_extractor.12.mlp.fc1.weight torch.Size([1536, 384]) 589824 True\n",
      "feature_extractor.12.mlp.fc1.bias torch.Size([1536]) 1536 True\n",
      "feature_extractor.12.mlp.fc2.weight torch.Size([384, 1536]) 589824 True\n",
      "feature_extractor.12.mlp.fc2.bias torch.Size([384]) 384 True\n",
      "feature_extractor.13.0.weight torch.Size([384]) 384 True\n",
      "feature_extractor.13.0.bias torch.Size([384]) 384 True\n",
      "feature_extractor.13.1.weight torch.Size([768, 384, 2, 2]) 1179648 True\n",
      "feature_extractor.13.1.bias torch.Size([768]) 768 True\n",
      "feature_extractor.14.gamma torch.Size([768]) 768 True\n",
      "feature_extractor.14.conv_dw.weight torch.Size([768, 1, 7, 7]) 37632 True\n",
      "feature_extractor.14.conv_dw.bias torch.Size([768]) 768 True\n",
      "feature_extractor.14.norm.weight torch.Size([768]) 768 True\n",
      "feature_extractor.14.norm.bias torch.Size([768]) 768 True\n",
      "feature_extractor.14.mlp.fc1.weight torch.Size([3072, 768]) 2359296 True\n",
      "feature_extractor.14.mlp.fc1.bias torch.Size([3072]) 3072 True\n",
      "feature_extractor.14.mlp.fc2.weight torch.Size([768, 3072]) 2359296 True\n",
      "feature_extractor.14.mlp.fc2.bias torch.Size([768]) 768 True\n",
      "feature_extractor.15.gamma torch.Size([768]) 768 True\n",
      "feature_extractor.15.conv_dw.weight torch.Size([768, 1, 7, 7]) 37632 True\n",
      "feature_extractor.15.conv_dw.bias torch.Size([768]) 768 True\n",
      "feature_extractor.15.norm.weight torch.Size([768]) 768 True\n",
      "feature_extractor.15.norm.bias torch.Size([768]) 768 True\n",
      "feature_extractor.15.mlp.fc1.weight torch.Size([3072, 768]) 2359296 True\n",
      "feature_extractor.15.mlp.fc1.bias torch.Size([3072]) 3072 True\n",
      "feature_extractor.15.mlp.fc2.weight torch.Size([768, 3072]) 2359296 True\n",
      "feature_extractor.15.mlp.fc2.bias torch.Size([768]) 768 True\n",
      "feature_extractor.16.gamma torch.Size([768]) 768 True\n",
      "feature_extractor.16.conv_dw.weight torch.Size([768, 1, 7, 7]) 37632 True\n",
      "feature_extractor.16.conv_dw.bias torch.Size([768]) 768 True\n",
      "feature_extractor.16.norm.weight torch.Size([768]) 768 True\n",
      "feature_extractor.16.norm.bias torch.Size([768]) 768 True\n",
      "feature_extractor.16.mlp.fc1.weight torch.Size([3072, 768]) 2359296 True\n",
      "feature_extractor.16.mlp.fc1.bias torch.Size([3072]) 3072 True\n",
      "feature_extractor.16.mlp.fc2.weight torch.Size([768, 3072]) 2359296 True\n",
      "feature_extractor.16.mlp.fc2.bias torch.Size([768]) 768 True\n",
      "trainable_layers:\n",
      "[   'proxies',\n",
      "    'conv1_emb.Allen',\n",
      "    'conv1_emb.CP',\n",
      "    'conv1_emb.HPA',\n",
      "    'hypernet.W',\n",
      "    'hypernet.b',\n",
      "    'hypernet.W_out',\n",
      "    'hypernet.b_out',\n",
      "    'feature_extractor.0.weight',\n",
      "    'feature_extractor.0.bias',\n",
      "    'feature_extractor.1.blocks.0.gamma',\n",
      "    'feature_extractor.1.blocks.0.conv_dw.weight',\n",
      "    'feature_extractor.1.blocks.0.conv_dw.bias',\n",
      "    'feature_extractor.1.blocks.0.norm.weight',\n",
      "    'feature_extractor.1.blocks.0.norm.bias',\n",
      "    'feature_extractor.1.blocks.0.mlp.fc1.weight',\n",
      "    'feature_extractor.1.blocks.0.mlp.fc1.bias',\n",
      "    'feature_extractor.1.blocks.0.mlp.fc2.weight',\n",
      "    'feature_extractor.1.blocks.0.mlp.fc2.bias',\n",
      "    'feature_extractor.1.blocks.1.gamma',\n",
      "    'feature_extractor.1.blocks.1.conv_dw.weight',\n",
      "    'feature_extractor.1.blocks.1.conv_dw.bias',\n",
      "    'feature_extractor.1.blocks.1.norm.weight',\n",
      "    'feature_extractor.1.blocks.1.norm.bias',\n",
      "    'feature_extractor.1.blocks.1.mlp.fc1.weight',\n",
      "    'feature_extractor.1.blocks.1.mlp.fc1.bias',\n",
      "    'feature_extractor.1.blocks.1.mlp.fc2.weight',\n",
      "    'feature_extractor.1.blocks.1.mlp.fc2.bias',\n",
      "    'feature_extractor.1.blocks.2.gamma',\n",
      "    'feature_extractor.1.blocks.2.conv_dw.weight',\n",
      "    'feature_extractor.1.blocks.2.conv_dw.bias',\n",
      "    'feature_extractor.1.blocks.2.norm.weight',\n",
      "    'feature_extractor.1.blocks.2.norm.bias',\n",
      "    'feature_extractor.1.blocks.2.mlp.fc1.weight',\n",
      "    'feature_extractor.1.blocks.2.mlp.fc1.bias',\n",
      "    'feature_extractor.1.blocks.2.mlp.fc2.weight',\n",
      "    'feature_extractor.1.blocks.2.mlp.fc2.bias',\n",
      "    'feature_extractor.2.downsample.0.weight',\n",
      "    'feature_extractor.2.downsample.0.bias',\n",
      "    'feature_extractor.2.downsample.1.weight',\n",
      "    'feature_extractor.2.downsample.1.bias',\n",
      "    'feature_extractor.2.blocks.0.gamma',\n",
      "    'feature_extractor.2.blocks.0.conv_dw.weight',\n",
      "    'feature_extractor.2.blocks.0.conv_dw.bias',\n",
      "    'feature_extractor.2.blocks.0.norm.weight',\n",
      "    'feature_extractor.2.blocks.0.norm.bias',\n",
      "    'feature_extractor.2.blocks.0.mlp.fc1.weight',\n",
      "    'feature_extractor.2.blocks.0.mlp.fc1.bias',\n",
      "    'feature_extractor.2.blocks.0.mlp.fc2.weight',\n",
      "    'feature_extractor.2.blocks.0.mlp.fc2.bias',\n",
      "    'feature_extractor.2.blocks.1.gamma',\n",
      "    'feature_extractor.2.blocks.1.conv_dw.weight',\n",
      "    'feature_extractor.2.blocks.1.conv_dw.bias',\n",
      "    'feature_extractor.2.blocks.1.norm.weight',\n",
      "    'feature_extractor.2.blocks.1.norm.bias',\n",
      "    'feature_extractor.2.blocks.1.mlp.fc1.weight',\n",
      "    'feature_extractor.2.blocks.1.mlp.fc1.bias',\n",
      "    'feature_extractor.2.blocks.1.mlp.fc2.weight',\n",
      "    'feature_extractor.2.blocks.1.mlp.fc2.bias',\n",
      "    'feature_extractor.2.blocks.2.gamma',\n",
      "    'feature_extractor.2.blocks.2.conv_dw.weight',\n",
      "    'feature_extractor.2.blocks.2.conv_dw.bias',\n",
      "    'feature_extractor.2.blocks.2.norm.weight',\n",
      "    'feature_extractor.2.blocks.2.norm.bias',\n",
      "    'feature_extractor.2.blocks.2.mlp.fc1.weight',\n",
      "    'feature_extractor.2.blocks.2.mlp.fc1.bias',\n",
      "    'feature_extractor.2.blocks.2.mlp.fc2.weight',\n",
      "    'feature_extractor.2.blocks.2.mlp.fc2.bias',\n",
      "    'feature_extractor.3.0.weight',\n",
      "    'feature_extractor.3.0.bias',\n",
      "    'feature_extractor.3.1.weight',\n",
      "    'feature_extractor.3.1.bias',\n",
      "    'feature_extractor.4.gamma',\n",
      "    'feature_extractor.4.conv_dw.weight',\n",
      "    'feature_extractor.4.conv_dw.bias',\n",
      "    'feature_extractor.4.norm.weight',\n",
      "    'feature_extractor.4.norm.bias',\n",
      "    'feature_extractor.4.mlp.fc1.weight',\n",
      "    'feature_extractor.4.mlp.fc1.bias',\n",
      "    'feature_extractor.4.mlp.fc2.weight',\n",
      "    'feature_extractor.4.mlp.fc2.bias',\n",
      "    'feature_extractor.5.gamma',\n",
      "    'feature_extractor.5.conv_dw.weight',\n",
      "    'feature_extractor.5.conv_dw.bias',\n",
      "    'feature_extractor.5.norm.weight',\n",
      "    'feature_extractor.5.norm.bias',\n",
      "    'feature_extractor.5.mlp.fc1.weight',\n",
      "    'feature_extractor.5.mlp.fc1.bias',\n",
      "    'feature_extractor.5.mlp.fc2.weight',\n",
      "    'feature_extractor.5.mlp.fc2.bias',\n",
      "    'feature_extractor.6.gamma',\n",
      "    'feature_extractor.6.conv_dw.weight',\n",
      "    'feature_extractor.6.conv_dw.bias',\n",
      "    'feature_extractor.6.norm.weight',\n",
      "    'feature_extractor.6.norm.bias',\n",
      "    'feature_extractor.6.mlp.fc1.weight',\n",
      "    'feature_extractor.6.mlp.fc1.bias',\n",
      "    'feature_extractor.6.mlp.fc2.weight',\n",
      "    'feature_extractor.6.mlp.fc2.bias',\n",
      "    'feature_extractor.7.gamma',\n",
      "    'feature_extractor.7.conv_dw.weight',\n",
      "    'feature_extractor.7.conv_dw.bias',\n",
      "    'feature_extractor.7.norm.weight',\n",
      "    'feature_extractor.7.norm.bias',\n",
      "    'feature_extractor.7.mlp.fc1.weight',\n",
      "    'feature_extractor.7.mlp.fc1.bias',\n",
      "    'feature_extractor.7.mlp.fc2.weight',\n",
      "    'feature_extractor.7.mlp.fc2.bias',\n",
      "    'feature_extractor.8.gamma',\n",
      "    'feature_extractor.8.conv_dw.weight',\n",
      "    'feature_extractor.8.conv_dw.bias',\n",
      "    'feature_extractor.8.norm.weight',\n",
      "    'feature_extractor.8.norm.bias',\n",
      "    'feature_extractor.8.mlp.fc1.weight',\n",
      "    'feature_extractor.8.mlp.fc1.bias',\n",
      "    'feature_extractor.8.mlp.fc2.weight',\n",
      "    'feature_extractor.8.mlp.fc2.bias',\n",
      "    'feature_extractor.9.gamma',\n",
      "    'feature_extractor.9.conv_dw.weight',\n",
      "    'feature_extractor.9.conv_dw.bias',\n",
      "    'feature_extractor.9.norm.weight',\n",
      "    'feature_extractor.9.norm.bias',\n",
      "    'feature_extractor.9.mlp.fc1.weight',\n",
      "    'feature_extractor.9.mlp.fc1.bias',\n",
      "    'feature_extractor.9.mlp.fc2.weight',\n",
      "    'feature_extractor.9.mlp.fc2.bias',\n",
      "    'feature_extractor.10.gamma',\n",
      "    'feature_extractor.10.conv_dw.weight',\n",
      "    'feature_extractor.10.conv_dw.bias',\n",
      "    'feature_extractor.10.norm.weight',\n",
      "    'feature_extractor.10.norm.bias',\n",
      "    'feature_extractor.10.mlp.fc1.weight',\n",
      "    'feature_extractor.10.mlp.fc1.bias',\n",
      "    'feature_extractor.10.mlp.fc2.weight',\n",
      "    'feature_extractor.10.mlp.fc2.bias',\n",
      "    'feature_extractor.11.gamma',\n",
      "    'feature_extractor.11.conv_dw.weight',\n",
      "    'feature_extractor.11.conv_dw.bias',\n",
      "    'feature_extractor.11.norm.weight',\n",
      "    'feature_extractor.11.norm.bias',\n",
      "    'feature_extractor.11.mlp.fc1.weight',\n",
      "    'feature_extractor.11.mlp.fc1.bias',\n",
      "    'feature_extractor.11.mlp.fc2.weight',\n",
      "    'feature_extractor.11.mlp.fc2.bias',\n",
      "    'feature_extractor.12.gamma',\n",
      "    'feature_extractor.12.conv_dw.weight',\n",
      "    'feature_extractor.12.conv_dw.bias',\n",
      "    'feature_extractor.12.norm.weight',\n",
      "    'feature_extractor.12.norm.bias',\n",
      "    'feature_extractor.12.mlp.fc1.weight',\n",
      "    'feature_extractor.12.mlp.fc1.bias',\n",
      "    'feature_extractor.12.mlp.fc2.weight',\n",
      "    'feature_extractor.12.mlp.fc2.bias',\n",
      "    'feature_extractor.13.0.weight',\n",
      "    'feature_extractor.13.0.bias',\n",
      "    'feature_extractor.13.1.weight',\n",
      "    'feature_extractor.13.1.bias',\n",
      "    'feature_extractor.14.gamma',\n",
      "    'feature_extractor.14.conv_dw.weight',\n",
      "    'feature_extractor.14.conv_dw.bias',\n",
      "    'feature_extractor.14.norm.weight',\n",
      "    'feature_extractor.14.norm.bias',\n",
      "    'feature_extractor.14.mlp.fc1.weight',\n",
      "    'feature_extractor.14.mlp.fc1.bias',\n",
      "    'feature_extractor.14.mlp.fc2.weight',\n",
      "    'feature_extractor.14.mlp.fc2.bias',\n",
      "    'feature_extractor.15.gamma',\n",
      "    'feature_extractor.15.conv_dw.weight',\n",
      "    'feature_extractor.15.conv_dw.bias',\n",
      "    'feature_extractor.15.norm.weight',\n",
      "    'feature_extractor.15.norm.bias',\n",
      "    'feature_extractor.15.mlp.fc1.weight',\n",
      "    'feature_extractor.15.mlp.fc1.bias',\n",
      "    'feature_extractor.15.mlp.fc2.weight',\n",
      "    'feature_extractor.15.mlp.fc2.bias',\n",
      "    'feature_extractor.16.gamma',\n",
      "    'feature_extractor.16.conv_dw.weight',\n",
      "    'feature_extractor.16.conv_dw.bias',\n",
      "    'feature_extractor.16.norm.weight',\n",
      "    'feature_extractor.16.norm.bias',\n",
      "    'feature_extractor.16.mlp.fc1.weight',\n",
      "    'feature_extractor.16.mlp.fc1.bias',\n",
      "    'feature_extractor.16.mlp.fc2.weight',\n",
      "    'feature_extractor.16.mlp.fc2.bias']\n",
      "\n",
      "Total parameters: 28,253,952;\tTrainable: 28,253,952\n",
      " total_params 28253952, trainable_params 28253952\n",
      "Pytorch version: 2.0.0\n",
      "Cuda version: 11.7\n",
      "Cudnn version: 8500\n",
      "loaded model from ../STORE/adaptive_interface/checkpoints/hypernet.pt, epoch 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load trainer (including model) from the checkpoint \n",
    "## the model can be accessed by `trainer.model`\n",
    "\n",
    "trainer = Trainer(cfg)\n",
    "checkpoint_path = os_join(cfg.train.checkpoints, cfg.train.resume_model)\n",
    "trainer._load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5f9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the dataloader\n",
    "chunk_name = \"HPA\"  ## \"HPA\", \"CP\", \"Allen\"\n",
    "eval_loader = trainer.test_loaders[chunk_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f0c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict on the first batch\n",
    "for bid, batch in enumerate(eval_loader, 1):\n",
    "    x = utils.move_to_cuda(batch, trainer.device)\n",
    "    output = trainer._forward_model(x, chunk_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41880f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3708e-01,  4.8151e-01,  1.3948e+00,  2.6062e-01, -1.0426e+00,\n",
       "         -1.1895e+00, -8.3807e-02, -4.9599e-01, -5.3987e-01,  4.6434e-01,\n",
       "          1.4282e+00, -8.1709e-01, -1.8891e-01, -7.6706e-01,  7.9759e-01,\n",
       "         -8.7906e-01, -3.0676e-01,  4.2329e-01,  2.0100e+00, -3.2558e-02,\n",
       "          8.6898e-01,  2.0236e-01, -1.8164e+00, -1.8529e+00, -1.9424e+00,\n",
       "         -3.7470e-01, -1.9068e+00,  1.4251e-01,  9.2694e-01,  2.1006e+00,\n",
       "          6.6473e-01, -2.8709e+00,  8.8675e-01,  1.6067e+00, -4.3679e-01,\n",
       "          1.2245e+00, -1.2845e+00,  7.1122e-01, -1.2272e+00, -8.9891e-01,\n",
       "          1.0262e+00,  3.5620e-01,  1.5320e+00, -3.2812e-01,  2.8977e-01,\n",
       "         -4.2916e-01, -5.5874e-01, -6.4917e-01,  7.1124e-01, -6.1677e-01,\n",
       "          7.2687e-01, -9.0863e-01,  1.1209e+00,  4.2012e-01,  2.8815e-02,\n",
       "         -1.4981e+00,  8.1967e-01, -1.0982e+00, -4.7885e-01, -1.1211e-01,\n",
       "          2.6869e-01, -5.2503e-02,  4.9140e-02,  3.4887e+00, -2.4342e+00,\n",
       "          4.6784e-02, -4.1378e-01, -1.3993e+00, -6.7539e-01, -8.6512e-01,\n",
       "          1.0999e+00, -1.3961e-01, -1.1320e+00,  5.4489e-01,  1.8501e+00,\n",
       "         -2.1115e+00, -7.9778e-01,  1.3994e+00,  3.3120e-01, -8.6994e-01,\n",
       "         -2.4316e-01, -5.6643e-01, -6.4163e-01,  1.4834e+00,  5.1572e-01,\n",
       "         -4.3021e-01, -6.5990e-01,  5.9809e-01,  3.0317e-01,  1.7402e-01,\n",
       "         -4.4249e+00, -2.1892e+00, -4.6932e-01, -7.1530e-01,  1.2516e+00,\n",
       "          6.9640e-01, -2.1230e+00, -1.1318e+00, -1.7067e-01,  3.1401e-01,\n",
       "         -2.1096e-01, -1.0537e+00,  5.1911e-01,  7.1231e-01, -7.8758e-01,\n",
       "          6.3953e-01, -6.2131e-02,  1.1129e+00,  1.3648e+00,  5.4481e-01,\n",
       "          1.8758e+00, -4.7558e-01,  9.8974e-01, -6.7219e-01,  7.2699e-01,\n",
       "          6.7731e-01, -1.0697e+00, -5.9505e-02, -5.5612e-01, -1.8945e-01,\n",
       "          1.0935e+00,  8.5104e-01, -1.0494e+00,  2.1523e+00, -9.0934e-01,\n",
       "         -9.0064e-01, -9.3066e-02,  6.4527e-01, -2.9965e-01,  8.1542e-01,\n",
       "         -4.9808e-02, -2.2947e+00,  6.6000e-01,  3.1951e-01,  2.1881e+00,\n",
       "         -1.8827e-01,  9.7269e-02, -9.7108e-01, -3.7933e-01, -7.4491e-01,\n",
       "         -1.3031e-01,  1.1021e+00, -5.5441e-01,  2.1982e+00,  1.6631e+00,\n",
       "          3.1587e+00, -1.7050e+00, -1.4929e+00,  1.6083e+00,  1.6366e+00,\n",
       "         -6.0519e-01, -2.9763e+00,  3.6538e-01,  7.5102e-01, -7.9197e-01,\n",
       "         -1.4106e-02, -7.2570e-01,  3.5897e-01,  6.0039e-01,  2.0505e+00,\n",
       "          7.8251e-01, -4.5426e-01,  1.7345e+00,  3.9100e-01,  5.7378e-01,\n",
       "          5.5177e-01,  5.0483e-01,  5.8136e-01,  1.0884e+00, -1.0839e+00,\n",
       "         -1.3951e+00,  1.1455e+00,  3.0244e-01,  8.9620e-01,  8.5231e-01,\n",
       "         -4.4302e-01,  2.8206e-01, -1.1791e-01, -5.8600e-02, -8.9060e-01,\n",
       "         -2.2970e-01, -2.4197e+00,  2.1821e+00,  9.7321e-01, -9.4170e-01,\n",
       "          7.2403e-01,  8.6860e-01,  5.7931e-01, -1.4998e+00, -1.2797e+00,\n",
       "          4.8747e-02, -1.2605e+00,  1.9158e+00,  1.8886e+00,  3.5993e-01,\n",
       "         -3.0524e+00,  7.5406e-01, -8.3701e-03, -4.5055e-01, -8.4506e-01,\n",
       "         -2.4404e-01, -1.1408e+00, -2.2090e-01, -8.7194e-02, -1.5905e+00,\n",
       "          3.0658e-03, -1.4929e+00, -1.4875e-01,  6.6183e-01,  1.4777e+00,\n",
       "         -5.7066e-01,  8.0644e-01,  4.9180e-01, -9.2133e-02,  3.4989e+00,\n",
       "         -1.0247e+00,  9.2463e-01, -2.6535e-01, -1.1574e+00,  4.5480e-01,\n",
       "         -1.4433e+00, -2.1201e-01, -9.1021e-01, -1.7722e+00, -2.2448e-01,\n",
       "          1.0200e-01,  2.7270e+00, -1.2795e+00,  9.7855e-01, -1.9237e+00,\n",
       "         -2.4308e+00,  3.6901e-02,  2.3058e-01,  5.1572e-01, -9.7280e-02,\n",
       "         -4.4904e-01, -4.7237e-01,  4.6669e-02,  1.1861e+00,  2.1744e+00,\n",
       "         -5.7748e-01,  4.5280e-01,  2.3043e-02,  5.0614e-02,  3.3606e-01,\n",
       "          2.5132e-01,  7.5158e-01,  4.4164e-01, -5.0640e-01, -9.6661e-02,\n",
       "          2.1482e+00,  4.8398e-01, -1.1849e+00,  3.3295e-01, -3.1439e-01,\n",
       "         -6.8389e-01,  2.9317e-01,  9.7289e-01,  9.9629e-01, -4.9029e-01,\n",
       "          6.8605e-01, -1.8675e+00, -7.0988e-01, -7.5606e-01, -1.9940e-01,\n",
       "         -2.8019e-01,  1.7504e-01, -2.4583e+00, -6.6623e-01,  3.1792e-01,\n",
       "          1.0236e+00, -2.2494e+00,  6.4366e-01,  8.7918e-02, -2.0199e+00,\n",
       "          2.4795e+00, -1.2290e+00, -8.3386e-01, -5.0115e-01, -4.8096e-01,\n",
       "          1.1414e-01,  1.6455e+00, -2.7850e-01,  9.8894e-01, -8.9899e-01,\n",
       "          1.0486e+00,  1.6218e-01, -2.7966e-02,  1.1583e+00,  2.8478e-01,\n",
       "          8.8853e-01,  8.2888e-02,  3.9474e-01,  3.2409e-01, -1.4857e+00,\n",
       "          6.9214e-01, -3.4603e-01, -1.1388e+00,  2.7340e-01, -1.2300e+00,\n",
       "         -1.0003e+00, -1.7760e+00,  3.7560e-01, -1.1702e+00, -1.7151e+00,\n",
       "         -9.0842e-01,  1.4983e+00,  1.5090e-01,  1.7285e-01, -1.0175e-01,\n",
       "          1.1945e+00, -2.2593e+00, -2.9001e-01,  2.1834e+00, -5.3418e-01,\n",
       "          1.9384e+00, -1.8419e-02,  1.0196e+00, -1.4336e+00, -1.7712e-01,\n",
       "         -3.9569e-01,  2.2196e-02, -1.3377e+00,  1.1073e+00, -2.5301e+00,\n",
       "         -3.0683e-01,  5.7736e-01, -6.9363e-01,  1.2564e-02, -7.1635e-01,\n",
       "          9.7489e-01, -3.7296e-02, -8.9066e-01, -4.8263e-01, -1.4393e+00,\n",
       "         -2.5211e-02, -2.3156e-01, -8.7869e-02,  1.3433e-01, -7.9790e-01,\n",
       "         -1.7727e-01, -3.0170e-02,  4.2085e-01,  1.7451e+00,  8.8197e-01,\n",
       "          7.5041e-01, -8.8019e-01, -3.0669e-01, -1.3424e+00,  8.3236e-01,\n",
       "          2.2046e-01, -1.2260e+00, -4.3387e-01, -3.5105e-01,  6.0738e-02,\n",
       "         -1.1126e+00, -2.5020e-01,  2.1452e-01,  1.0581e+00,  9.0031e-02,\n",
       "         -1.2470e+00,  2.2754e+00, -1.3244e+00, -5.1212e-01, -1.0093e+00,\n",
       "         -4.4548e-01, -6.2087e-01, -2.6408e-01, -1.5532e+00,  1.4276e+00,\n",
       "          1.2025e+00, -5.1873e-01,  7.4842e-01,  3.3179e-01,  2.2146e+00,\n",
       "          1.7856e-01,  1.4817e+00, -4.1790e-01, -3.3305e+00,  2.6755e-01,\n",
       "         -3.0986e-01,  5.4431e-01,  2.2573e-01,  3.7991e-01, -9.6333e-03,\n",
       "         -1.1052e+00,  6.1963e-01,  9.4169e-01,  1.0508e+00,  3.2082e-01,\n",
       "          1.0553e+00, -1.0805e-01,  1.3585e+00, -1.9577e+00, -5.8254e-01,\n",
       "         -8.2528e-03, -1.3789e+00,  8.1792e-01,  4.4149e-01,  2.3541e-01,\n",
       "          1.6881e+00, -1.7025e+00, -2.2630e+00, -9.2534e-01, -1.0008e-01,\n",
       "         -1.1610e+00,  1.0749e+00,  4.0088e-01,  1.3245e+00, -9.3783e-01,\n",
       "          2.5182e-01,  6.1967e-01, -1.8830e+00,  3.2084e-01, -5.0874e-02,\n",
       "         -8.9398e-01, -1.0984e+00, -7.0656e-01, -2.7026e+00,  6.6922e-03,\n",
       "         -1.8588e+00, -4.9833e-01,  9.5794e-01,  2.8514e-01,  2.2886e+00,\n",
       "         -1.3632e+00,  1.3736e+00,  3.5778e-01,  3.3839e-02, -1.0449e+00,\n",
       "         -2.1787e-01,  7.0391e-01,  5.6623e-01, -3.1102e-01, -6.4749e-01,\n",
       "          1.2444e+00,  2.1461e-01, -9.7066e-01, -4.9519e-01,  2.4851e+00,\n",
       "          5.6321e-01,  1.4927e+00,  1.9230e-01, -2.6326e+00, -7.6081e-01,\n",
       "          5.2195e-01, -5.5860e-01, -7.6356e-01, -7.7166e-01, -8.1384e-01,\n",
       "         -1.4354e+00,  8.4563e-01,  1.4213e+00, -4.2536e-01, -1.3038e+00,\n",
       "         -9.8957e-01,  8.3079e-01, -1.3714e-01, -4.6905e-01,  8.4789e-01,\n",
       "          6.7169e-01, -1.7735e+00,  5.8346e-01,  5.2905e-01, -4.1464e-02,\n",
       "          5.6224e-01, -2.9872e-03, -2.3888e-02,  2.5746e+00,  1.6630e+00,\n",
       "          2.2702e+00, -9.8102e-01, -2.0466e-01,  1.5163e-01,  2.3544e-01,\n",
       "         -2.9285e+00,  1.0926e+00,  6.0047e-01, -7.7959e-01, -6.6075e-01,\n",
       "          7.1002e-01, -1.6241e-01, -1.8077e+00, -3.5088e-01,  1.2427e+00,\n",
       "         -1.6010e+00,  2.4942e+00,  1.0232e+00,  1.4233e+00,  1.5679e+00,\n",
       "         -4.9156e-01,  1.0226e+00,  1.7650e+00, -3.6386e+00, -8.7955e-01,\n",
       "         -1.7002e+00, -7.7975e-01, -8.8681e-01,  2.4353e-01,  1.0143e+00,\n",
       "          2.6453e-01,  7.5678e-01, -5.9141e-01,  7.7564e-01,  8.2759e-01,\n",
       "         -3.6346e-01, -5.7442e-01,  2.8860e-02, -9.4663e-01, -3.6674e-01,\n",
       "         -2.6581e-01, -1.4512e+00, -7.4205e-01,  1.9288e+00, -1.5502e+00,\n",
       "         -7.5452e-01,  5.7583e-01, -4.7340e-01,  1.2886e+00, -5.8150e-01,\n",
       "          6.9411e-01, -2.7831e-01,  4.2730e+00, -1.2424e+00, -6.7984e-02,\n",
       "          7.3546e-02,  2.0489e+00,  2.2175e-01, -1.0441e+00,  1.8606e+00,\n",
       "         -1.2085e+00, -1.3777e+00, -1.3050e+00, -1.2699e+00,  2.5482e-01,\n",
       "          3.0268e+00,  7.4294e-01, -1.1242e+00, -1.3381e+00,  1.1110e+00,\n",
       "         -2.3476e-01, -3.0271e+00,  1.0592e-01,  2.6638e+00, -5.7007e-01,\n",
       "          1.6757e+00,  1.2885e+00,  5.4063e-02, -1.5768e+00, -2.2409e+00,\n",
       "         -4.8115e-01,  1.4931e+00, -6.3417e-01,  8.9292e-01, -3.7430e-01,\n",
       "         -1.1620e-01, -1.5448e+00, -1.5180e-01,  4.0525e-01, -4.7447e-01,\n",
       "         -3.7573e-01, -1.6689e+00,  9.2035e-01,  1.8571e+00, -9.5321e-01,\n",
       "          8.8342e-02,  1.2031e+00,  6.4652e-01,  7.2768e-01, -1.9359e-01,\n",
       "          1.0001e+00,  4.5235e-01, -4.0750e-01,  1.2572e+00,  2.1657e+00,\n",
       "         -1.8266e+00, -5.7565e-01,  8.8156e-02,  6.6421e-02, -3.1861e-01,\n",
       "         -5.2842e-01,  4.1348e-01,  5.9249e-01,  8.3812e-02, -2.9266e-01,\n",
       "         -1.1284e-02, -1.5746e+00, -6.4861e-02,  1.4520e-01, -1.3522e-01,\n",
       "          1.6610e-01, -5.5274e-01,  1.8361e+00,  9.6309e-01,  2.2941e-01,\n",
       "         -1.6390e+00, -1.4049e-01, -7.1209e-01,  1.3085e+00, -3.1062e+00,\n",
       "         -1.2219e+00, -5.4391e-01, -3.8946e-01, -4.1267e-01, -2.7951e+00,\n",
       "          7.1305e-01, -5.5359e-01, -1.0559e+00, -1.3153e+00, -1.1168e+00,\n",
       "         -8.6594e-01, -1.7027e-01, -1.6947e-01, -8.4743e-02,  1.2474e+00,\n",
       "          7.5065e-01,  2.4034e+00,  6.0200e-02,  5.8931e-01, -2.1588e+00,\n",
       "          4.1436e-01, -1.4000e+00,  6.9871e-01,  5.7720e+00, -2.1432e-01,\n",
       "         -1.0779e+00, -1.1694e+00,  1.2614e-01,  8.3949e-01,  1.1927e+00,\n",
       "         -2.7572e-01, -1.8232e+00, -1.9906e+00,  6.2693e-01, -5.0776e-01,\n",
       "         -2.2482e-01, -2.5151e+00, -1.4390e-02,  1.8699e-01,  5.3109e-01,\n",
       "         -9.9276e-01, -5.1367e-01, -4.9065e-01, -1.1234e+00,  4.1058e-01,\n",
       "          1.3952e+00,  3.8104e-01,  3.4317e-01, -8.9919e-01,  8.4565e-01,\n",
       "          9.9341e-01, -1.5485e-01, -1.3159e-01,  3.7935e-02,  8.7885e-01,\n",
       "         -2.5788e+00,  3.3595e-01, -6.2760e-01,  1.0186e-01,  1.8020e+00,\n",
       "         -3.5320e-01,  1.2763e+00,  1.4262e+00, -2.2560e-01, -2.5929e-01,\n",
       "          7.7486e-01,  5.7118e-02, -2.1307e+00, -7.1065e-01,  3.5823e-01,\n",
       "          5.8273e-01,  3.1437e+00,  4.1790e-01, -7.6315e-01, -2.1988e+00,\n",
       "         -1.0117e-01,  1.8055e-01, -8.3549e-01,  1.4129e+00, -2.8955e-01,\n",
       "          8.2464e-01,  3.0141e-01, -3.0592e-01,  1.0081e+00,  3.6531e-01,\n",
       "          2.2349e+00,  1.5900e+00,  1.5858e-01, -2.9621e-01, -2.6749e-01,\n",
       "         -8.2826e-01,  3.3458e-01, -1.3654e+00, -4.0497e-01,  8.4883e-01,\n",
       "          9.6353e-02, -3.9518e-03,  2.3450e-01, -4.5336e-01, -2.8364e+00,\n",
       "          3.2287e-01, -6.0201e-03,  7.9165e-01,  5.3538e-01,  2.7423e+00,\n",
       "         -2.8847e-01, -7.4627e-01,  1.0779e-01, -7.9778e-01, -4.7702e-01,\n",
       "         -3.8330e-01,  8.0834e-01,  1.0110e+00,  3.1719e-01,  2.2346e+00,\n",
       "         -1.1879e+00, -6.6945e-01, -1.9504e-01,  1.8884e+00,  1.3410e+00,\n",
       "          9.5908e-01, -3.0153e-02,  1.6463e-01,  2.2874e-01,  9.4740e-01,\n",
       "          3.4472e-01,  6.2204e-01,  2.1132e-01,  1.5385e+00,  8.7757e-01,\n",
       "          3.6161e+00, -2.4343e-01, -1.1585e+00,  1.2304e-01, -1.5345e+00,\n",
       "          1.0151e+00, -1.2667e+00, -3.1739e-01, -3.3785e-01, -1.4235e+00,\n",
       "         -1.9383e-02, -4.8373e-01,  7.0360e-01, -3.7364e-01, -4.4594e-01,\n",
       "         -1.8339e+00,  1.3014e+00, -2.2562e+00, -5.2048e-02, -1.2316e+00,\n",
       "         -2.6765e-01,  4.4857e-01, -7.2283e-02,  2.2794e+00,  1.5780e-01,\n",
       "         -8.9977e-01, -1.2717e+00,  1.1484e-01,  2.1777e+00,  6.4720e-02,\n",
       "         -9.0143e-01, -9.7120e-01,  2.0037e+00, -1.0061e-01,  1.1264e+00,\n",
       "         -9.7674e-01, -9.7867e-01, -4.7329e-01]], device='cuda:0',\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## output\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c763811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9454b8a4",
   "metadata": {},
   "source": [
    "To evaluate on the whole dataset to get the metrics and visualization:\n",
    "\n",
    "```trainer.eval_morphem70k(0)```\n",
    "\n",
    "Note: you may want to use a larger eval batch_size for evaluation. This will take a while to complete the run.\n",
    "\n",
    "\n",
    "For more details on the evaluation package, please visit https://github.com/broadinstitute/MorphEm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
